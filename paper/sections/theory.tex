\section{Theory}

% \begin{itemize}
%     \item What is deconvolution and different formulations presented as a review.
%     \item Analysis vs synthesis
%     \begin{itemize}
%         \item TA paper but without the spatial regularization
%         \item PFM paper
%         \item In Gitelman it's an \(\mathbf{H}\) multiplied by a Fourier term.
%     \end{itemize}
%     \item Spikes and block models
% \end{itemize}

The hemodynamic response to neuronal activity can be modeled as the convolution the activity-inducing signal \(s(t)\) with the hemodynamic response function \(h(t)\) as \(x(t) = h(t) * s(t)\) (\citealt{gitelman2003ModelingRegionalPsychophysiologic}). Then, the fMRI signal at a given voxel \(y(t)\) can be decomposed into neuronal-related hemodynamic \(x(t)\) and noise components \(n(t)\) as:
\begin{equation}
    \label{eq:gitelman}
    y(t) = x(t) + n(t).
\end{equation}

The maximum likelihood estimate of the hemodynamic response to the underlying neural activity can be calculated using the ordinary least-squares estimator that minimizes the residual sum of squares between the modeled (\(\mathbf{X}\)) and measured (\(\mathbf{y}\)) signals. In conventional fMRI data analysis, when the information about the timings of the BOLD events is known, the activity inducing signal, also known as the stimulus function of a condition of interest, is retrieved by solving a general linear model (GLM) problem such that:
\begin{equation}
    \label{eq:glm}
    \mathbf{y} = \mathbf{X \beta} + \mathbf{n},
\end{equation}
where the measured signal (\(\mathbf{y}\)) is described as the sum of one or more experimental design variables (\(\mathbf{X}\)), each multiplied by a weighting factor (\(\mathbf{\beta}\)). The signal model in~\eqref{eq:gitelman} can also be extended to represent the neuronal signal \(\mathbf{s}\) in terms of its innovation signal \(\mathbf{u}\), i.e., its derivative, as \(\mathbf{s} = \mathbf{Lu}\) where \(\mathbf{L} \in \mathbb{R}^{N \times N}\) is an integration operator (\citealt{cherkaoui2019SparsitybasedBlindDeconvolution,urunuela2020StabilityBasedSparseParadigm}). Thus, the GLM problem in \eqref{eq:glm} can be rewritten as \(\mathbf{y} = \mathbf{X L \beta} + \mathbf{n}\) to detect changes that drive the neuronal signal.

Yet, when the information about the timings of the BOLD events is unavailable, the design matrix \(\mathbf{X}\) has to be described as the Toeplitz convolution matrix with shifted HRFs (see Figure~\ref{fig:hrf_diff}B). In this case, the estimates of the neuronal activity \(\mathbf{s}\) must be constrained with a regularization term to attenuate the collinearity and high variability of the new design matrix \(\mathbf{H}\), and the estimation of the underlying neural activity becomes a deconvolution problem such that:
\begin{equation}
    \label{eq:deconvolution}
    \mathbf{y} = \mathbf{Hs} + \mathbf{n},
\end{equation}
where \(\mathbf{y, s} \in \mathbb{R}^N\), \(\mathbf{H} \in \mathbb{R}^{N \times N}\) is the HRF in Toeplitz matrix form, and \(N\) is the number of frames of the fMRI acquisition.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Paradigm Free Mapping
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Synthesis-based deconvolution}

Synthesis-based deconvolution models are those in which the candidate estimator is synthesized (i.e. constructed) from a linear combination of dictionary atoms. Paradigm Free Mapping (PFM) is based on such construction as its estimator \(\mathbf{H}\) is described by shifted HRFs (atoms). Hence, considering the signal model introduced in~\eqref{eq:gitelman}; i.e., the BOLD signal (\(\mathbf{x}\)) is the result of convolving the underlying neural activity (\(\mathbf{s}\)) with the hemodynamic response (\(\mathbf{H}\)), the activity-inducing signal can be estimated by solving the following regularized least-squares problem (\citealt{gaudes2011DetectionCharacterizationSingletrial,caballerogaudes2013ParadigmFreeMapping,urunuela2020StabilityBasedSparseParadigm}):
\begin{equation}
    \label{eq:pfm}
    \hat{\mathbf{s}} = \arg \min_{\mathbf{s}} \frac{1}{2} \| \mathbf{y} - \mathbf{Hs} \|_2^2 + \Omega(\mathbf{s}),
\end{equation}
where \(\Omega(\mathbf{s})\) is the regularization term.

Assuming that single-trial BOLD responses are the result of brief bursts of neuronal activation, the activity-inducing signal \(\mathbf{s}\) must be a sparse vector. Thus, sparse estimates of \(\mathbf{s}\) could be obtained by substituting \(\Omega(\mathbf{s})\) in~\eqref{eq:pfm} with an \(l_0\)-norm and solving the optimization problem (\citealt{bruckstein2009SparseSolutionsSystems}). However, due to the convolution model defined in~\eqref{eq:pfm}, finding the optimal solution to the problem demands an exhaustive search across all possible combinations of the columns of the design matrix \(\mathbf{H}\). Hence, a pragmatic solution is to solve the optimization problem with the use of an \(l_1\)-norm, or LASSO (\citealt{tibshirani1996RegressionShrinkageSelection}), which is a convex function and therefore provides fast convergence to the optimal solution.
\begin{equation}
    \label{eq:pfm_spike}
    \hat{\mathbf{s}} = \arg \min_{\mathbf{s}} \frac{1}{2} \| \mathbf{y} - \mathbf{Hs} \|_2^2 + \lambda \| \mathbf{s} \|_1,
\end{equation}
where \(\lambda\) regulates how sparse the optimal solution is.

Such formulation provides flexibility to expand the capabilities of PFM. For instance, incorporating the integration operator \(\mathbf{L}\) into the design matrix \(\mathbf{H}\) allows the recovery of the innovation signal \(\mathbf{u}\); i.e., the derivative of the activity-inducing signal \(\mathbf{s}\). Therefore, the innovation signal can be estimated by solving the following optimization problem (\citealt{cherkaoui2019SparsitybasedBlindDeconvolution,urunuela2020StabilityBasedSparseParadigm}):
\begin{equation}
    \label{eq:pfm_block}
    \hat{\mathbf{u}} = \arg \min_{\mathbf{u}} \frac{1}{2} \| \mathbf{y} - \mathbf{HLu} \|_2^2 + \lambda \| \mathbf{u} \|_1.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Total Activation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Analysis-based deconvolution}

On the other hand, the estimator of the signal is analyzed in analysis-based deconvolution models, i.e., some aspects of it are calculated and penalized during the estimation process. For instance, Total Activation (TA) proposes to use a linear differential operator \(L_h\) that inverts the hemodynamic system based on activelets to recover the activity-inducing signal \(\mathbf{s}\) (\citealt{karahanoglu2013TotalActivationFMRI,khalidov2011activelets,karahanoglu2011SignalProcessingApproacha}):
\begin{equation}
    L_h\{x\}(t) = s(t)
\end{equation}
where \(x\) is the neuronal-related signal; i.e., the activity inducing signal \(\mathbf{s}\) convolved with the HRF, and \(L_h\) is defined as
\begin{equation}
    L_h\ = \prod_{i=1}^{M_1} (D-\alpha_i I) (\prod_{j=1}^{M_2} (D - \gamma_j I))^{-1},
\end{equation}
where \(D\) is the derivative operator, \(\alpha_i (i=1, \hdots, M_1)\) define the zeros of the filter, \(\gamma_j (j=1, \hdots, M_2)\) represent the poles, \(I\) is the identity matrix and \(M_1 > M_2\). Given the relationship between the activity-inducing and the innovation signal, the latter can be recovered as:
\begin{equation}
    L\{x\}(t) = D\{s\}(t) = u(t)
\end{equation}
where \(L = DL_h\) and \(D\) is the derivative.

Therefore, for a given voxel, the neuronal-related signal could be estimated by solving the following regularized least-squares problem:
\begin{equation}
    \hat{\mathbf{x}} = \arg \min_{\mathbf{x}} \frac{1}{2} \| \mathbf{y} - \mathbf{x} \|_2^2 + \Omega(\mathbf{x}),
\end{equation}
where \(\mathbf{y}\) is the fMRI data and \(\mathcal{R}(\mathbf{x})\) is the following \(l_1\)-norm regularization term:
\begin{equation}
    \hat{\mathbf{x}} = \arg \min_{\mathbf{x}} \frac{1}{2} \| \mathbf{y} - \mathbf{x} \|_2^2 + \lambda \| \Delta_L \{\mathbf{x}\} \|_1,
\end{equation}
where \(\lambda\) is the regularization parameter.

This work evaluates the core of the two techniques, i.e., the regularized least-squares problem with temporal regularization, which corresponds to the generalized total-variation operator in Total Activation. Therefore, we do not study the impact of spatial constraints, as we assume that spatial regularization terms should perform identically on both methods.

\subsection{Selection of the regularization parameter}
\label{sec:regparam}

The correct selection of the regularization parameter \(\lambda\) is a critical decision for the accurate performance of deconvolution methods. Even though many techniques have been proposed in the literature, the optimal strategy that selects \(\lambda\) is yet to be found. Algorithms like least angle regression (LARS) (\citealt{efron2004LeastAngleRegression}) provide all the possible solutions to the optimization problem and their corresponding value of \(\lambda\), i.e., the regularization path, but don't provide the optimal solution. Therefore, strategies that exploit the regularization path can provide a selection of \(\lambda\) that is close to the optimal. For instance, in Paradigm Free Mapping, the optimal result is given by the Bayesian Information Criterion (BIC) (\citealt{schwarz1978EstimatingDimensionModel}), i.e., the regularization path solution with the minimum BIC is considered optimal. Another approach could be to update the regularization parameter \(\lambda\) on every iteration \(n\) like Total Activation does, so that the residuals converge to a previously estimated noise level of the data fit \(\tilde{\sigma}\). The pre-estimated noise level is calculated from the median absolute deviation of fine-scale wavelet coefficients (Daubechies, order 3) (\citealt{karahanoglu2013TotalActivationFMRI}):
\begin{equation}
    \lambda^{n+1} = \frac{N \tilde{\sigma}}{\frac{1}{2} \| \mathbf{y} - \mathbf{x}^n \|_F^2} \lambda^n.
\label{eq:std}
\end{equation}

Here, we compare the performance of the two deconvolution algorithms with both selection criteria and in terms of the estimation of the activity-inducing signal \(\mathbf{s}\) using the \textit{spike model} in~\eqref{eq:pfm_spike} and the innovation signal \(\mathbf{u}\) using the \textit{block model} in~\eqref{eq:pfm_block}.