% !TEX root = ../main.tex

\section{Introduction}

% \begin{itemize}

%     \item Talk about our motivation for this paper.

%     \item We could mention iCAPs Neuron, and papers with applications like PFM, TA, clinical patient papers with iCAPs.

%     \item Apart from [[Richard F. Betzel]]'s work~\citealt{betzel2020temporal,esfahlani2020high,faskowitz2020edge}, we could mention the connection with the
%     [[Multiplication of Temporal Derivatives]] method~\citealt{shine2015estimation,shine2016dynamics}.

%     \begin{itemize}
%         \item These are basically calculating the derivative, which is the same as applying a high-pass filter and calculating the correlation.
%     \end{itemize}

% \end{itemize}

% Footnote example
% \fntext[myfootnote]{Since 1880.}

Functional magnetic resonance imaging (fMRI) data analysis is often directed to identify and disentangle the neural processes that occur in different brain regions during task or at rest. As the blood oxygenation level-dependent (BOLD) signal of fMRI is only a proxy for neuronal activity mediated through neurovascular coupling, an intermediate step that estimates the activity-inducing signal, at the timescale of fMRI, from the BOLD timeseries can be useful. Conventional analysis of task fMRI data relies on the general linear models (GLM) to establish statistical parametric maps of brain activity by regression of the empirical timecourses against hypothetical ones built from the knowledge of the experimental paradigm. However, timing information of the paradigm can be unknown, inaccurate, or insufficient in some scenarios such as naturalistic stimuli, resting-state, or clinically-relevant assessments.

Deconvolution and methods alike are aiming to estimate neuronal activity by undoing the blurring effect of the hemodynamic response, characterized as a hemodynamic response function (HRF). Given the inherently ill-posed nature of hemodynamic deconvolution, due to the strong temporal low-pass characteristics of the HRF, the key is to introduce additional constraints in the estimation problem that are typically expressed as regularizers. For instance, the so-called Wiener deconvolution is expressing a ``minimal energy'' constraint on the deconvolved signal, and has been used in the framework of psychophysiological interaction analysis to compute the interaction between a seed's activity-inducing timecourse and an experimental modulation (\citealt{Glover1999DeconvolutionImpulseResponse,Gitelman2003Modelingregionalpsychophysiologic,Gerchen2014Analyzingtaskdependent,Di2018TaskConnectomicsExamining,Freitas2020Timeresolvedeffective}). Complementarily, the interest in deconvolution has increased to explore time-varying activity in resting-state fMRI data (\citealt{Preti2017dynamicfunctionalconnectome,Keilholz2017TimeResolvedResting,Lurie2020Questionscontroversiesstudy,Bolton2020TappingMultiFaceted}). In that case, the aim is to gain better insights of the neural signals that drive functional connectivity at short time scales, as well as learning about the spatio-temporal structure of functional components that dynamically construct resting-state networks and their interactions (\citealt{Karahanoglu2017Dynamicslargescale}).

Deconvolution of the resting-state fMRI signal has illustrated the significance of transient, sparse spontaneous events (\citealt{Petridou2012PeriodsrestfMRI,Allan2015FunctionalConnectivityMRI}) that refine the hierarchical clusterization of functional networks (\citealt{Karahanoglu2013TotalactivationfMRI}) and reveal their temporal overlap based on their signal innovations not only in the human brain (\citealt{Karahanoglu2015Transientbrainactivity}), but also in the spinal cord (\citealt{kinany2020DynamicFunctionalConnectivity}). Similar to task-related studies, deconvolution allows to investigate modulatory interactions within and between resting-state functional networks (\citealt{Di2013ModulatoryInteractionsResting,Di2015Characterizationsrestingstate}). In addition, decoding of the deconvolved spontaneous events allows to decipher the flow of spontaneous thoughts and actions across different cognitive and sensory domains while at rest (\citealt{Karahanoglu2015Transientbrainactivity,GonzalezCastillo2019Imagingspontaneousflow,Tan_2017}). Beyond findings on healthy subjects, deconvolution techniques have also proven its utility in clinical conditions to characterize functional alterations of patients with a progressive stage of multiple sclerosis at rest (\citealt{Bommarito2020Alteredanteriordefault}), to find functional signatures of prodromal psychotic symptoms and anxiety at rest on patients suffering from schizophrenia (\citealt{Zoeller2019Largescalebrain}), to detect the foci of interictal events in epilepsy patients without an EEG recording (\citealt{Lopes2012Detectionepilepticactivity,Karahanoglu2013Spatialmappinginterictal}), or to study functional dissociations observed during non-rapid eye movement sleep that are associated with reduced consolidation of information and impaired consciousness (\citealt{Tarun2020NREMsleepstages}).

The algorithms for hemodynamic deconvolution can be classified based on the assumed hemodynamic model and the optimization problem used to estimate the neuronal-related signal. Most approaches assume a linear time-invariant model for the hemodynamic response that is inverted by means of variational (regularized) least squares estimators (\citealt{Glover1999DeconvolutionImpulseResponse,Gitelman2003Modelingregionalpsychophysiologic,Gaudes2010Detectioncharacterizationsingle,Gaudes2012Structuredsparsedeconvolution,Gaudes2013Paradigmfreemapping,CaballeroGaudes2019deconvolutionalgorithmmulti,HernandezGarcia2011Neuronaleventdetection,Karahanoglu2013TotalactivationfMRI,Cherkaoui2019SparsitybasedBlind,Costantini2021ParadigmFreeRegularization,Huetel2021Hemodynamicmatrixfactorization}), logistic functions (\citealt{Bush2013Decodingneuralevents,Bush2015deconvolutionbasedapproach,Loula2018DecodingfMRIactivity}), probabilistic mixture models (\citealt{Pidnebesna2019EstimatingSparseNeuronal}), convolutional autoencoders (\citealt{Huetel2018NeuralActivationEstimation}) or nonparametric homomorphic filtering (\citealt{Sreenivasan2015NonparametricHemodynamicDeconvolution}). Alternatively, several methods have also been proposed to invert non-linear models of the neuronal and hemodynamic coupling (\citealt{Riera2004statespacemodel,Friston2008DEMvariationaltreatment,Havlicek2011Dynamicmodelingneuronal,Aslan2016Jointstateparameter,Madi2017HybridCubatureKalman,ruizeuler2018nonlinear}). 

Among the variety of approaches, those based on regularized least squares estimators have been employed more often due to their appropriate performance at small spatial scales (e.g., voxelwise). Relevant for this work, two different formulations can be established for the regularized least-squares deconvolution problem, either based on a synthesis- or analysis-based model (\citealt{Elad2007Analysisversussynthesis,ortelli2019synthesis}). The rationale of the synthesis-based model is that we know or suspect that the true signal (here, the neuronally-driven BOLD component of the fMRI signal) can be represented as a linear combination of predefined patterns or dictionary atoms (for instance, the hemodynamic response function). In contrast, the analysis-based approach considers that the true signal is analyzed by some relevant operator and the resulting signal is small (i.e., sparse).

As the authors of the Paradigm Free Mapping (synthesis-based) and Total Activation (analysis-based) deconvolution methods for fMRI data analysis, we are often contacted by researchers who want to know about the differences between the two methods and which one of them is better. In order to give an answer to these questions, this note revisits synthesis- and analysis-based deconvolution methods for fMRI data and comprises four sections. First, we present the theory behind these two deconvolution approaches based on regularized least squares estimators that promote sparsity: Paradigm Free Mapping (PFM) (\citealt{Gaudes2013Paradigmfreemapping}) --- available in AFNI as \textit{3dPFM}\footnote{\url{https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dPFM.html}} and \textit{3dMEPFM}\footnote{\url{https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dMEPFM.html}} for single-echo and multi-echo data, respectively --- and Total Activation (TA) (\citealt{Karahanoglu2013TotalactivationfMRI}) --- available as part of the \textit{iCAPs toolbox}\footnote{\url{https://c4science.ch/source/iCAPs/}}. Next, we assess their performance controlling for a fair comparison on simulated and experimental data. Finally, we discuss the benefits and shortcomings of each technique and conclude with our vision on potential extensions and developments.
\todo[inline]{Here we create an expectation that there will only be differences between the two methods. Maybe we should already announce in what aspects they are similar/different.}

As the authors of the Paradigm Free Mapping (synthesis-based) and Total Activation (analysis-based) deconvolution methods for fMRI data analysis, we are often contacted by researchers who want to know about the similarties and differences between the two methods and which one is better. In order to give an answer to these questions, this note revisits synthesis- and analysis-based deconvolution methods for fMRI data and comprises four sections. First, we present the theory behind these two deconvolution approaches based on regularized least squares estimators that promote sparsity: Paradigm Free Mapping (PFM) (\citealt{Gaudes2013Paradigmfreemapping}) --- available in AFNI as \textit{3dPFM}\footnote{\url{https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dPFM.html}} and \textit{3dMEPFM}\footnote{\url{https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dMEPFM.html}} for single-echo and multi-echo data, respectively --- and Total Activation (TA) (\citealt{Karahanoglu2013TotalactivationfMRI}) --- available as part of the \textit{iCAPs toolbox}\footnote{\url{https://c4science.ch/source/iCAPs/}}. We describe the similarities and differences in their formulations, and how they can be related to each other. Next, we assess their performance controlling for a fair comparison on simulated and experimental data. Finally, we discuss their benefits and shortcomings and conclude with our vision on potential extensions and developments.