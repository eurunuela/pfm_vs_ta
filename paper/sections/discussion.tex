% !TEX root = ../main.tex

\section{Discussion and conclusion}

Hemodynamic deconvolution can be formulated using a synthesis- and
analysis-based approach as proposed by PFM and TA, respectively. This work
demonstrates that the theoretical equivalence of PFM and TA is confirmed in
practice given virtually identical results when the same HRF model and
equivalent regularization parameters are employed. Hence, we argue that
previously observed differences in performance can be explained by specific
settings, such as the HRF model and selection of the regularization parameter,
convergence thresholds, as well as the addition of a spatial regularization term
in the spatiotemporal TA formulation \citep{Karahanoglu2013TotalactivationfMRI}.
\textcolor{blue}{For instance, the use of PFM with the spike model in
\citep{Tan_2017} was seen not to be ideal due to the prolonged trials in the
paradigm, which might be better described with the block model.} However, given the equivalence of
the temporal deconvolution, incorporating extra spatial or temporal
regularization terms in the optimization problem should not modify this
equivalence providing convex operators are employed. For a convex optimization
problem, with a unique global solution, iterative shrinkage thresholding
procedures alternating between the different regularization terms guarantee
convergence; e.g., the generalizgoed forward-backward splitting
\citep{Raguet2013GeneralizedForwardBackward} algorithm originally employed for
TA. Our findings are also in line with the equivalence of analysis and synthesis
methods in under-determined cases (\(N \leq V\)) demonstrated in
\citep{Elad2007Analysisversussynthesis} and \citep{ortelli2019synthesis}. Still,
we have shown that a slight difference in the selection of the regularization
parameter can lead to small differences in the estimated signals when employing
the block model with the MAD selection of $\lambda$. However, since their
regularization paths are equivalent, the algorithms can easily be forced to
converge to the same selection of $\lambda$, thus resulting in identical
estimated signals.

Nevertheless, the different formulations of analysis and synthesis deconvolution
models bring along different kinds of flexibility. One notable advantage of PFM
is that it can readily incorporate any HRF as part of the synthesis operator
\citep{Elad2007Analysisversussynthesis}, only requiring the sampled HRF at the
desired temporal resolution, which is typically equal to the TR of the
acquisition. Conversely, TA relies upon the specification of the discrete
differential operator that inverts the HRF, which needs to be derived either by
the inverse solution of the sampled HRF impulse response, or by discretizing a
continuous-domain differential operator motivated by a biophysical model. The
more versatile structure of PFM allows for instance an elegant extension of the
algorithm to multi-echo fMRI data
\citep{CaballeroGaudes2019deconvolutionalgorithmmulti} where multiple
measurements relate to a common underlying signal. Therefore, the one-to-many
synthesis scenario (i.e., from activity-inducing to several activity-related
signals) is more cumbersome to express using TA; i.e., a set of differential
operators should be defined and the differences between their outputs
constrained. Conversely, the one-to-many analysis scenario (i.e., from the
measurements to several regularizing signals) is more convenient to be expressed
by TA; e.g., combining spike and block regularizers. While the specification of
the differential operator in TA only indirectly controls the HRF, the use of the
derivative operator to enforce the block model, instead of the integrator in
PFM, impacts positively the stability and rate of the convergence of the
optimization algorithms. Moreover, analysis formulations can be more suitable
for online applications that are still to be explored in fMRI data, but are
employed for calcium imaging deconvolution \citep{Friedrich_2017,Jewell_2019},
and which have been applied for offline calcium deconvolution
\citep{Farouj2020DeconvolutionSustainedNeural}.
% \todo[inline]{The other point to further briefly develop here would be which
% type of optimization algorithms are accessible by both formulations. This
% would be an excellent point to be addressed by Younes. From what Hamza's PhD,
% the analysis formulation allows to use algorithms that are particularly
% efficient (e.g., FISTA family), but those are not portable to the synthesis
% case.}

Deconvolution techniques can be used before more downstream analysis of brain
activity in terms of functional network organization as they estimate
interactions between voxels or brain regions that occur at the activity-inducing
level, and are thus less affected by the slowness of the hemodynamic response
compared to when the BOLD signals are analyzed directly. In addition,
deconvolution approaches hold a close parallelism to recent methodologies aiming
to understand the dynamics of neuronal activations and interactions at short
temporal resolution and that focus on extreme events of the fMRI signal
\citep{Lindquist_2007}. As an illustration, Figure 6 shows that the innovation-
or activity-inducing CAPs computed from deconvolved events in a single
resting-state fMRI dataset closely resemble the conventional CAPs computed
directly from extreme events of the fMRI signal
\citep{Liu2013Timevaryingfunctional,Liu2013Decompositionspontaneousbrain,
Liu2018Coactivationpatterns,cifre2020revisiting,Cifre2020Furtherresultswhy,
Zhang2020relationshipBOLDneural,Tagliazucchi2011,Tagliazucchi2012,
Tagliazucchi2016,Rolls2021}. Similarly, we hypothesize that these extreme events
will also show a close resemblance to intrinsic ignition events
\citep{Deco2017a,Deco2017}. As shown in the maps, deconvolution approaches can
offer a more straightforward interpretability of the activation events and
resulting functional connectivity patterns. Here, CAPs were computed as the
average of spatial maps corresponding to the events of a single dataset. Beyond
simple averaging, clustering algorithms (e.g., K-means and consensus clustering)
can be employed to discern multiple CAPs or iCAPs at the whole-brain level for a
large number of subjects. Previous findings based on iCAPs have for instance
revealed organizational principles of brain function during rest
\citep{Karahanoglu2015Transientbrainactivity} and sleep \citep{tarun2101} in
healthy controls, next to alterations in 22q11ds \citep{zoller1902} and multiple
sclerosis \citep{bommarito2101p}. Next to CAPs-inspired approaches, dynamic
functional connectivity has recently been investigated with the use of
co-fluctuations and edge-centric techniques
\citep{Faskowitz2020,Esfahlani2020Highamplitudecofluctuations,Jo2021,Sporns2021,Oort2018}.
The activation time series shown in Figure 5 aim to provide equivalent
information to the root of sum of squares timecourses used in edge-centric
approaches, where timecourses with peaks delineate instances of significant
brain activity. Future work could address which type of information is redundant
or distinct across these frameworks. In summary, these examples illustrate that
deconvolution techniques can be employed prior to other computational approaches
and could serve as an effective way of denoising the fMRI data. We foresee an
increase in the number of studies that take advantage of the potential benefits
of using deconvolution methods prior to functional connectivity analyses.

In sum, hemodynamic deconvolution approaches using sparsity-driven
regularization are valuable tools to complete the fMRI processing pipeline.
Although the two approaches examined in detail here provide alternative
representations of the BOLD signals in terms of innovation and activity-inducing
signals, their current implementations have certain limitations, calling for
further developments or more elaborate models, where some of them have been
initially addressed in the literature. One relevant focus is to account for the
variability in HRF that can be observed in different regions of the brain. The
impact of HRF variability could be reduced using structured regularization terms
along with multiple basis functions
\citep{Gaudes2012Structuredsparsedeconvolution} or procedures that estimate the
HRF shape in an adaptive fashion in both analysis
\citep{Farouj2019BoldSignalDeconvolution} and synthesis formulations
\citep{cherkaoui:hal-03005584}. Another avenue of research consists in
leveraging spatial information by adopting multivariate deconvolution approaches
that operate at the whole-brain level, instead of working voxelwise and beyond
regional regularization terms (e.g. as proposed in
\citealt{Karahanoglu2013TotalactivationfMRI}).  Operating at the whole-brain
level would open the way for methods that consider shared neuronal activity
using mixed norm regularization terms \citep{urunuela-tremino_2019} or can
capture long-range neuronal cofluctuations using low rank decompositions
\citep{cherkaoui:hal-03005584}. For example, multivariate deconvolution
approaches could yield better localized activity patterns while reducing the
effect of global fluctuations such as respiratory artifacts, which cannot be
modelled at the voxel level \citealt{Urunuela_2021}. 

Similar to solving other inverse problems by means of regularized estimators,
the selection of the regularization parameter is critical to correctly estimate
the neuronal-related signal. Hence, methods that take advantage of a more robust
selection of the regularization parameter could considerably yield more reliable
estimates of the neuronal-related signal. For instance, the stability selection
\citep{Meinshausen2010Stabilityselection,Urunuela2020StabilityBasedSparse}
procedure could be included to the deconvolution problem to ensure that the
estimated coefficients are obtained with high probability. Furthermore, an
important issue of regularized estimation is that the estimates are biased with
respect to the true value. In that sense, the use of non-convex
\(\ell_{p,q}\)-norm regularization terms (e.g., \(p < 1\)) can reduce this bias
while maintaining the sparsity constraint, at the cost of potentially converging
to a local minima of the regularized estimation problem. In practice, these
approaches could avoid the optional debiasing step that overcomes the shrinkage
of the estimates and obtain a more accurate and less biased fit of the fMRI
signal
\citep{Gaudes2013Paradigmfreemapping,CaballeroGaudes2019deconvolutionalgorithmmulti}.
Finally, cutting-edge developments on physics-informed deep learning techniques
for inverse problems \citep{Akcakaya2021,Monga2021,Ongie2020,Cherkaoui_2020}
could be transferred for deconvolution by considering the biophysical model of
the hemodynamic system and could potentially offer algorithms with reduced
computational time and more flexibility.