% !TEX root = ../main.tex

\section{Discussion}

Hemodynamic deconvolution can be formulated using a synthesis- and analysis-based approach as proposed by PFM and TA, respectively. This work demonstrates that the theoretical equivalence of PFM and TA is confirmed in practice given virtually identical results when the same HRF model and equivalent regularization parameters are employed. Hence, we argue that previously observed differences in performance can be explained by specific settings, such as the HRF model and selection of the regularization parameter, convergence thresholds, as well as the addition of a spatial regularization term in the spatiotemporal TA formulation (\citealt{Karahanoglu2013TotalactivationfMRI}). However, given the equivalence of the temporal deconvolution, incorporating extra spatial or temporal regularization terms in the optimization problem should not modify this equivalence providing convex operators are employed. For a convex optimization problem, with a unique global solution, iterative shrinkage thresholding procedures alternating between the different regularization terms guarantee convergence; e.g., the generalized forward-backward splitting (\citealt{Raguet2013GeneralizedForwardBackward}) algorithm originally employed for TA. Our findings are also in line with the equivalence of analysis and synthesis methods in under-determined cases (\(N \leq V\)) demonstrated in (\citealt{Elad2007Analysisversussynthesis}) and (\citealt{ortelli2019synthesis}). Still, we have shown that a slight difference in the selection of the regularization parameter can lead to small differences in the estimated signals when employing the block model with the MAD selection of $\lambda$. However, since their regularization paths are equivalent, the algorithms can easily be forced to converge to the same selection of $\lambda$, thus resulting in identical estimated signals.

Nevertheless, the different formulations of analysis and synthesis deconvolution models bring along different kinds of flexibility. One notable advantage of PFM is that it can readily incorporate any HRF as part of the synthesis operator (\citealt{Elad2007Analysisversussynthesis}), only requiring the sampled HRF at the desired temporal resolution, which is typically equal to the TR of the acquisition. Conversely, TA relies upon the specification of the discrete differential operator that inverts the HRF, which needs to be derived either by the inverse solution of the sampled HRF impulse response, or by discretizing a continuous-domain differential operator motivated by a biophysical model. This more versatile structure of PFM allows for instance an elegant extension of the algorithm to multi-echo fMRI data (\citealt{CaballeroGaudes2019deconvolutionalgorithmmulti}) where multiple measurements relate to a common underlying signal. Such one-to-many synthesis scenario (i.e., from activity-inducing to several activity-related signals) is more cumbersome to express using TA; i.e., a set of differential operators should be defined and the differences between their output constrained. Conversely, a one-to-many analysis scenario (i.e., from the measurements to several regularizing signals) are more convenient to be expressed by TA; e.g., combining spike and block regularizers. 
While the specification of the differential operator in TA only indirectly controls the HRF, the use of the derivative operator to enforce the block model, instead of the integrator in PFM, impacts positively the stability and rate of the convergence of the optimization algorithms. Moreover, analysis formulations can be more suitable for online applications that are still to be explored in fMRI data but are employed for Calcium imaging deconvolution (\citealt{Friedrich_2017,Jewell_2019})\todo{Maybe you can add Younes' paper here too?}.
% \todo[inline]{The other point to further briefly develop here would be which type of optimization algorithms are accessible by both formulations. This would be an excellent point to be addressed by Younes. From what Hamza's PhD, the analysis formulation allows to use algorithms that are particularly efficient (e.g., FISTA family), but those are not portable to the synthesis case.}

Deconvolution techniques can be used before more downstream analysis of brain activity in terms of functional network organization as they estimate interactions between voxels or brain regions that occur at the activity-inducing level, and are thus less affected by the slowness of the hemodynamic response compared to when the BOLD signals are analyzed directly. In addition, deconvolution approaches hold a close parallelism to recent methodologies aiming to understand the dynamics of neuronal activations and interactions at short temporal resolution and that focus on extreme events of the fMRI signal (\citealt{Lindquist_2007}). As an illustration, Figure 6 shows that the innovation- or activity-inducing CAPs computed from deconvolved events in a single resting-state fMRI dataset closely resemble the conventional CAPs computed directly from extreme events of the fMRI signal (\citealt{Liu2013Timevaryingfunctional,Liu2013Decompositionspontaneousbrain,Liu2018Coactivationpatterns,cifre2020revisiting,Cifre2020Furtherresultswhy,Zhang2020relationshipBOLDneural,Tagliazucchi2011,Tagliazucchi2012,Tagliazucchi2016,Rolls2021}). Similarly, we hypothesize that these extreme events will also show a close resemblance to intrinsic ignition events (\citealt{Deco2017a,Deco2017}). As shown in the maps, deconvolution approaches can offer a more straightforward interpretability of the activation events and resulting functional connectivity patterns. Here, CAPs were computed as the average of spatial maps corresponding to the events of a single dataset. Beyond simple averaging, clustering algorithms (e.g., K-means and consensus clustering) can be employed to discern multiple CAPs or iCAPs at the whole-brain level for a large number of subjects. Previous findings based on iCAPs have for instance revealed organizational principles of brain function during rest (\citealt{Karahanoglu2015Transientbrainactivity}) and sleep (\citealt{tarun2101}) in healthy controls, next to alterations in 22q11ds (\citealt{zoller1902}) and multiple sclerosis (\citealt{bommarito2101p}). Next to CAPs-inspired approaches, dynamic functional connectivity has recently been investigated with the use of co-fluctuations and edge-centric techniques (\citealt{Faskowitz2020,Esfahlani2020Highamplitudecofluctuations,Jo2021,Sporns2021,Oort2018}). The activation time series shown in Figure 5 aim to provide equivalent information to the root of sum of squares timecourses used in edge-centric approaches, where timecourses with peaks delineate instances of significant brain activity. Future work could address which type of information is redundant or distinct across these frameworks. In summary, these examples illustrate that deconvolution techniques can be employed prior to other computational approaches and could serve as an effective way of denoising the fMRI data. We foresee an increase in the number of studies that take advantage of the potential benefits of using deconvolution methods prior to functional connectivity analyses.

In sum, hemodynamic deconvolution approaches using sparsity-driven regularization are valuable tools to complete the fMRI processing pipeline. Although the two approaches examined in detail here provide alternative representations of the BOLD signals in terms of innovation and activity-inducing signals, their current implementations have certain limitations, calling for further developments or more elaborate models, where some of them have been initially addressed in the literature. One relevant focus is to account for the variability in HRF that can be observed in different regions of the brain. The impact of HRF variability could be reduced using structured regularization terms along with multiple basis functions (\citealt{Gaudes2012Structuredsparsedeconvolution}) or procedures that estimate the HRF shape in an adaptive fashion in both analysis (\citealt{Farouj2019BoldSignalDeconvolution}) and synthesis formulations (\citealt{cherkaoui:hal-03005584}). Another avenue of research consists in leveraging spatial information by adopting multivariate deconvolution approaches that operate at the whole-brain level, instead of working voxelwise and beyond regional regularization terms (e.g. as proposed in  \citealt{Karahanoglu2013TotalactivationfMRI}).  Operating at the whole-brain level would open the way for methods that consider shared neuronal activity using mixed norm regularization terms (\citealt{urunuela-tremino_2019}) or can capture long-range neuronal cofluctuations using low rank decompositions (\citealt{cherkaoui:hal-03005584}). For example, multivariate deconvolution approaches could yield better localized activity patterns while reducing the effect of global fluctuations such as respiratory artifacts, which cannot be modelled at the voxel level \citealt{Urunuela_2021}. 
Similar to solving other inverse problems by means of regularized estimators, the selection of the regularization parameter is critical to correctly estimate the neuronal-related signal. Hence, methods that take advantage of a more robust selection of the regularization parameter could considerably yield more reliable estimates of the neuronal-related signal. For instance, the stability selection (\citealt{Meinshausen2010Stabilityselection,Urunuela2020StabilityBasedSparse}) procedure could be included to the deconvolution problem to ensure that the estimated coefficients are obtained with high probability. Furthermore, an important issue of regularized estimation is that the estimates are biased with respect to the true value. In that sense, the use of non-convex \(\ell_{p,q}\)-norm regularization terms (e.g., \(p < 1\)) can reduce this bias while maintaining the sparsity constraint, at the cost of potentially converging to a local minima of the regularized estimation problem. In practice, these approaches could avoid the optional debiasing step that overcomes the shrinkage of the estimates and obtain a more accurate and less biased fit of the fMRI signal (\citealt{Gaudes2013Paradigmfreemapping,CaballeroGaudes2019deconvolutionalgorithmmulti}). Finally, cutting-edge developments on physics-informed deep learning techniques for inverse problems (\citealt{Akcakaya2021,Monga2021,Ongie2020,Cherkaoui_2020}) could be transferred for deconvolution by considering the biophysical model of the hemodynamic system and could potentially offer algorithms with reduced computational time and more flexibility.